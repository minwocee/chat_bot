from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import google.generativeai as genai
import chromadb
from chromadb.utils import embedding_functions
import os
from dotenv import load_dotenv

# â”€â”€â”€ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# â”€â”€â”€ Gemini API ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-pro")    # gemini-1.5-pro    gemini-2.0-pro-exp-02-05

# â”€â”€â”€ ChromaDB í´ë¼ì´ì–¸íŠ¸ ë° ì»¬ë ‰ì…˜ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
chroma_client = chromadb.PersistentClient(path="./chroma_db")
embedding_fn = embedding_functions.OpenAIEmbeddingFunction(
    api_key=OPENAI_API_KEY,
    model_name="text-embedding-3-small"
)

collection_semantic = chroma_client.get_or_create_collection(
    name="semantic_education_chunks",
    embedding_function=embedding_fn
)

# â”€â”€â”€ FastAPI ì•± ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI()

# â”€â”€â”€ CORS ì„¤ì • (React í”„ë¡ íŠ¸ í—ˆìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€ ìš”ì²­ ë°”ë”” ëª¨ë¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class QueryRequest(BaseModel):
    query: str

# â”€â”€â”€ ì§ˆë¬¸ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/ask")
async def ask_question(request: QueryRequest):
    query = request.query.strip()
    top_k = 10

    try:
        results_semantic = collection_semantic.query(query_texts=[query], n_results=top_k)
    except Exception as e:
        return {"answer": f"DB ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

    retrieved_docs = []
    if results_semantic.get("documents"):
        retrieved_docs.extend(results_semantic["documents"][0])

    if not retrieved_docs:
        retrieved_docs = ["ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]

    # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
    retrieved_docs = list(dict.fromkeys(retrieved_docs))[:3]
    context = "\n".join(retrieved_docs)[:1500]

    prompt = f"""
    ë‹¹ì‹ ì€ ì»´í“¨í„°ê³µí•™ê³¼ ì‹ ì…ìƒë“¤ì˜ ê³¼ëª© ì„ íƒì„ ë„ì™€ì£¼ëŠ” ì¡°êµ ì±—ë´‡ì…ë‹ˆë‹¤.

    í•™ìƒë“¤ì€ ê³¼ëª© ìˆœì„œ, íŠ¸ë™ êµ¬ì„±, ì§„ë¡œì™€ ê´€ë ¨ëœ ìˆ˜ì—…ì„ ê³ ë¯¼í•˜ê³  ìˆìœ¼ë©°,  
    ë‹¹ì‹ ì€ ì´ë“¤ì—ê²Œ ë§ˆì¹˜ ìƒë‹´ ì„ ìƒë‹˜ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ ì¤ë‹ˆë‹¤.

    ê¸°ìˆ  ìš©ì–´(ì˜ˆ: ìœ„ìƒì •ë ¬, ìµœë‹¨ê²½ë¡œ)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ ,  
    ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.  
    "ë¨¼ì € ~ì„ ë“£ê³ , ê·¸ ë‹¤ìŒ ~ì„ ë“£ëŠ” ê²Œ ì¢‹ì•„ìš”" ê°™ì€ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.  
    ì¤‘ìš”í•œ ê³¼ëª©ì€ ê°•ì¡°í•´ë„ ì¢‹ì•„ìš”.  
    í•™ìƒë“¤ì´ í—·ê°ˆë¦¬ì§€ ì•Šë„ë¡ ìˆœì„œë¥¼ ì •ë¦¬í•´ì„œ ë§í•´ ì£¼ì„¸ìš”.

    ì£¼ì˜: ë‹µë³€ì—ëŠ” `*`, `**`, `-`, `â€¢` ë“±ê³¼ ê°™ì€ íŠ¹ìˆ˜ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ì•„ ì£¼ì„¸ìš”.  
    í•„ìš”í•œ ê²½ìš° ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ê°•ì¡°í•´ì£¼ì„¸ìš”.

    ë‹¤ìŒì€ ì°¸ê³  ì •ë³´ì…ë‹ˆë‹¤:
    {context}

    í•™ìƒì˜ ì§ˆë¬¸:
    {query}
    """

    try:
        response = model.generate_content(prompt)
        return {"answer": response.text}
    except Exception as e:
        return {"answer": f"Gemini ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

# â”€â”€â”€ ê¸°ë³¸ ë£¨íŠ¸ í…ŒìŠ¤íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/")
def root():
    return {"message": "ì»´ê³µë„ìš°ë¯¸ë´‡ APIê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤ ğŸš€"}