import google.generativeai as genai
import os
from dotenv import load_dotenv
import chromadb

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

#  Gemini API ì„¤ì •
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-2.0-pro-exp-02-05")

#  ChromaDB ì„¤ì •
chroma_client = chromadb.PersistentClient(path="./chroma_db")

#  ë‘ ê°œì˜ ì»¬ë ‰ì…˜ì„ ë¶ˆëŸ¬ì˜´
collection_report = chroma_client.get_or_create_collection(name="education_report")
collection_graph = chroma_client.get_or_create_collection(name="education_graph")

def get_gemini_answer(query, top_k=10):
    """ChromaDBì—ì„œ ë‘ ì»¬ë ‰ì…˜ì„ ê²€ìƒ‰ í›„ Geminië¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±"""
    
    #  ë‘ ì»¬ë ‰ì…˜ì—ì„œ ê°ê° ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    results_report = collection_report.query(query_texts=[query], n_results=top_k)
    results_graph = collection_graph.query(query_texts=[query], n_results=top_k)

    #  ë¬¸ì„œ í†µí•©
    retrieved_docs = []
    if results_report["documents"]:
        retrieved_docs.extend(results_report["documents"][0])
    if results_graph["documents"]:
        retrieved_docs.extend(results_graph["documents"][0])
    if not retrieved_docs:
        retrieved_docs = ["ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]

    context = "\n".join(retrieved_docs)

    prompt = f"""
    ë‹¹ì‹ ì€ ì»´í“¨í„°ê³µí•™ê³¼ ì‹ ì…ìƒë“¤ì˜ ê³¼ëª© ì„ íƒì„ ë„ì™€ì£¼ëŠ” ì¡°êµ ì±—ë´‡ì…ë‹ˆë‹¤.

    í•™ìƒë“¤ì€ ê³¼ëª© ìˆœì„œ, íŠ¸ë™ êµ¬ì„±, ì§„ë¡œì™€ ê´€ë ¨ëœ ìˆ˜ì—…ì„ ê³ ë¯¼í•˜ê³  ìˆìœ¼ë©°,  
    ë‹¹ì‹ ì€ ì´ë“¤ì—ê²Œ ë§ˆì¹˜ ìƒë‹´ ì„ ìƒë‹˜ì²˜ëŸ¼ ë¶€ë“œëŸ½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ ì¤ë‹ˆë‹¤.

    ê¸°ìˆ  ìš©ì–´(ì˜ˆ: ìœ„ìƒì •ë ¬, ìµœë‹¨ê²½ë¡œ)ëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³ ,  
    ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.  
    "ë¨¼ì € ~ì„ ë“£ê³ , ê·¸ ë‹¤ìŒ ~ì„ ë“£ëŠ” ê²Œ ì¢‹ì•„ìš”" ê°™ì€ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.  
    ì¤‘ìš”í•œ ê³¼ëª©ì€ ê°•ì¡°í•´ë„ ì¢‹ì•„ìš”.  
    í•™ìƒë“¤ì´ í—·ê°ˆë¦¬ì§€ ì•Šë„ë¡ ìˆœì„œë¥¼ ì •ë¦¬í•´ì„œ ë§í•´ ì£¼ì„¸ìš”.

    ì£¼ì˜: ë‹µë³€ì—ëŠ” `*`, `**`, `-`, `â€¢` ë“±ê³¼ ê°™ì€ íŠ¹ìˆ˜ ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ì•„ ì£¼ì„¸ìš”.  
    ë‚´ìš© ê°•ì¡°ë‚˜ ë¦¬ìŠ¤íŠ¸ í‘œí˜„ì´ í•„ìš”í•˜ë‹¤ë©´ ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„í•´ ì£¼ì„¸ìš”.  
    ì˜ˆ: "ê°€ì¥ ì¤‘ìš”í•œ ê³¼ëª©ì€ ~ì…ë‹ˆë‹¤." ë˜ëŠ” "ì¶”ì²œ ìˆœì„œëŠ” ~ì…ë‹ˆë‹¤." ì™€ ê°™ì´ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•´ ì£¼ì„¸ìš”.

    ê°€ë…ì„±ì´ ì¢‹ë„ë¡ ì¤„ë°”ê¿ˆì„ ì ì ˆíˆ í™œìš©í•˜ê³ , ë§ì´ ë„ˆë¬´ ê¸¸ì§€ ì•Šë„ë¡ ë¬¸ë‹¨ì„ ë‚˜ëˆ ì£¼ì„¸ìš”.
    ì•„ì´ì½˜ì„ í™œìš©í•´ì„œ ê°€ë…ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ”ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ì—ìš”.

    ë‹¤ìŒì€ ì°¸ê³  ì •ë³´ì…ë‹ˆë‹¤:
    {context}

    í•™ìƒì˜ ì§ˆë¬¸:
    {query}
    """

    response = model.generate_content(prompt)
    return response.text

#  ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ì‹¤í–‰
if __name__ == "__main__":
    print("ì•ˆë…•í•˜ì„¸ìš”! ì»´ê³µë„ìš°ë¯¸ë´‡ ì…ë‹ˆë‹¤. ì–´ë–¤ ì§ˆë¬¸ì„ í•˜ê³ ì‹¶ìœ¼ì‹ ê°€ìš”?")
    query_text = input("\nì§ˆë¬¸: ")
    answer = get_gemini_answer(query_text)
    print("\nğŸ”¹ ì»´ê³µë„ìš°ë¯¸ë´‡ ë‹µë³€:")
    # print(answer.replace('**', ''))
